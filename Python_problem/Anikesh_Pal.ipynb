{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anikesh_Pal.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "e54LCSXICMph",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**All Scripting is performed in Google colab**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zamkM7r4iBYm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json as js\n",
        "import tweepy as tp\n",
        "import pandas as pd\n",
        "def extract_midastweets():\n",
        "    customer_key=\"\" #Key Removed\n",
        "    customer_secret_key=\"\" #Key Removed\n",
        "    api_access_key=\"\" #Key Removed\n",
        "    api_access_secret=\"\" #Key Removed\n",
        "    auth=tp.OAuthHandler(customer_key,customer_secret_key) \n",
        "    auth.set_access_token(api_access_key,api_access_secret) \n",
        "    api=tp.API(auth) \n",
        "    user_tweets=api.user_timeline(screen_name=\"midasIIITD\")\n",
        "    tweets_list=list()\n",
        "    for i in user_tweets:\n",
        "        tweet=dict()\n",
        "        tweet[\"text of the tweet\"] = i.text\n",
        "        tweet[\"date and time of the tweet\"] = str(i.created_at)\n",
        "        tweet[\"number of favorites/likes\"] = i.favorite_count\n",
        "        tweet[\"number of retweets\"] = i.retweet_count\n",
        "        if \"media\" in i.entities:\n",
        "            tweet[\"number of images\"] = len(i.entities[\"media\"])\n",
        "        else:\n",
        "            tweet[\"number of images\"] = \"None\"\n",
        "        tweets_list.append(tweet)\n",
        "    json_file=open(\"midastweets.json\",\"w\")\n",
        "    js.dump(tweets_list,json_file)\n",
        "    json_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7idCp2R2iExu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def display_tweets():    \n",
        "    json_file = open(\"midastweets.json\",\"r\")\n",
        "    tweets=js.load(json_file)\n",
        "    json_file.close()\n",
        "    headers=[\"text of the tweet\",\"date and time of the tweet\",\"number of favorites/likes\",\"number of retweets\",\"number of images\"]\n",
        "    df=pd.DataFrame(columns=headers,data=tweets)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MKPabK2VBHPt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        },
        "outputId": "15d6eba3-4576-457e-a63f-62a054fce6a3"
      },
      "cell_type": "code",
      "source": [
        "extract_midastweets()\n",
        "print(display_tweets())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                    text of the tweet  \\\n",
            "0   Clarification: Our earlier post which indicate...   \n",
            "1   RT @IIITDelhi: Applications open for MTech (CB...   \n",
            "2   RT @IIITDelhi: We are delighted to share that ...   \n",
            "3   RT @Harvard: Professor Jelani Nelson founded A...   \n",
            "4   RT @emnlp2019: For anyone interested in submit...   \n",
            "5   RT @multimediaeval: Announcing the 2019 MediaE...   \n",
            "6   Many Congratulations to @midasIIITD student, S...   \n",
            "7   @midasIIITD thanks all students who have appea...   \n",
            "8   @himanchalchandr Meanwhile, complete CV/NLP ta...   \n",
            "9   @sayangdipto123 Submit as per the guideline ag...   \n",
            "10  We request all students whose interview are sc...   \n",
            "11  Other queries: \"none of the Tweeter Apis give ...   \n",
            "12  Other queries: \"do we have to make two differe...   \n",
            "13  Other queries: \"If using Twitter api, it does ...   \n",
            "14  Response to some queries asked by students on ...   \n",
            "15  RT @kdnuggets: Top 8 #Free Must-Read #Books on...   \n",
            "16  @nupur_baghel @PennDATS Congratulation @nupur_...   \n",
            "17  We have emailed the task details to all candid...   \n",
            "18  RT @rfpvjr: Our NAACL paper on polarization in...   \n",
            "19  RT @kdnuggets: Effective Transfer Learning For...   \n",
            "\n",
            "   date and time of the tweet  number of favorites/likes  number of retweets  \\\n",
            "0         2019-04-10 09:01:29                          0                   0   \n",
            "1         2019-04-10 04:51:26                          0                   1   \n",
            "2         2019-04-09 16:45:07                          0                  14   \n",
            "3         2019-04-09 05:04:27                          0                  36   \n",
            "4         2019-04-09 05:04:11                          0                  17   \n",
            "5         2019-04-08 19:38:09                          0                  15   \n",
            "6         2019-04-08 07:08:12                         18                   2   \n",
            "7         2019-04-08 03:27:42                          5                   0   \n",
            "8         2019-04-07 14:17:29                          0                   0   \n",
            "9         2019-04-07 14:17:09                          0                   0   \n",
            "10        2019-04-07 11:43:24                          1                   1   \n",
            "11        2019-04-07 06:55:19                          5                   2   \n",
            "12        2019-04-07 06:53:38                          5                   1   \n",
            "13        2019-04-07 05:32:27                          6                   1   \n",
            "14        2019-04-07 05:29:40                          7                   1   \n",
            "15        2019-04-06 17:11:29                          0                   2   \n",
            "16        2019-04-06 16:43:27                         18                   3   \n",
            "17        2019-04-05 16:08:37                         11                   1   \n",
            "18        2019-04-05 04:05:11                          0                  16   \n",
            "19        2019-04-05 04:04:43                          0                  11   \n",
            "\n",
            "   number of images  \n",
            "0              None  \n",
            "1              None  \n",
            "2              None  \n",
            "3              None  \n",
            "4              None  \n",
            "5              None  \n",
            "6              None  \n",
            "7              None  \n",
            "8              None  \n",
            "9              None  \n",
            "10             None  \n",
            "11             None  \n",
            "12             None  \n",
            "13             None  \n",
            "14             None  \n",
            "15             None  \n",
            "16             None  \n",
            "17             None  \n",
            "18             None  \n",
            "19                1  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qFZpHPSFiP1-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}